{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae8c3ba-fda5-4487-ad16-119d9bdc7854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prati\\AppData\\Local\\Temp\\ipykernel_21456\\184282149.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   35.1s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import surprise\n",
    "from surprise.model_selection import GridSearchCV, KFold\n",
    "import pickle\n",
    "\n",
    "# Function to preprocess data and build the recommendation model\n",
    "def preprocess_and_build_model(df):\n",
    "    # Convert 'product_id' column to string type\n",
    "    df['product_id'] = df['product_id'].astype(str)\n",
    "\n",
    "    # Function to convert product ID to generic alphabetic product name based on category\n",
    "    def convert_product_name(row):\n",
    "        category = row['product_category_name_english']\n",
    "        product_id = row['product_id']  # No need to convert to string now\n",
    "        # Create a generic product name by concatenating category abbreviation and a numerical index\n",
    "        category_abbreviation = ''.join(word[:].upper() for word in category.split())\n",
    "        index = int(''.join(filter(str.isdigit, product_id)))  # Extract numerical part from product_id\n",
    "        product_name = f'{category_abbreviation}_{index}'\n",
    "        return product_name\n",
    "\n",
    "    # Convert product IDs to product names\n",
    "    df['product_name'] = df.apply(convert_product_name, axis=1)\n",
    "\n",
    "    # Preprocess the data\n",
    "    lowest_rating = df['review_score'].min()\n",
    "    highest_rating = df['review_score'].max()\n",
    "\n",
    "    # Create a dictionary to map unique customer IDs to sequential numbers\n",
    "    id_mapping = {id_: idx + 1 for idx, id_ in enumerate(df['customer_id'].unique())}\n",
    "\n",
    "    # Convert customer IDs to simple generic unique numbers\n",
    "    df['customer_id'] = df['customer_id'].map(id_mapping)\n",
    "\n",
    "    # Define the Reader\n",
    "    reader = surprise.Reader(rating_scale=(lowest_rating, highest_rating))\n",
    "    data = surprise.Dataset.load_from_df(df[['customer_id', 'product_name', 'review_score']], reader)\n",
    "\n",
    "    # Grid search for best parameters\n",
    "    param_grid = {'lr_all': np.linspace(0.001, 1, 3), 'reg_all': np.linspace(0.01, 0.8, 3),\n",
    "                  'n_factors': [40, 30]}\n",
    "    kfold = KFold(random_state=23, n_splits=5, shuffle=True)\n",
    "    gs = GridSearchCV(surprise.SVD, param_grid, joblib_verbose=3, measures=['rmse', 'mae'], cv=kfold, n_jobs=-1)\n",
    "    gs.fit(data)\n",
    "\n",
    "    algo = gs.best_estimator['rmse']\n",
    "    algo.fit(data.build_full_trainset())\n",
    "\n",
    "    # Dumping the model using pickle\n",
    "    with open('recommendation_model.pkl', 'wb') as model_file:\n",
    "        pickle.dump(algo, model_file)\n",
    "\n",
    "    # Dumping id_mapping for later use\n",
    "    with open('id_mapping.pkl', 'wb') as id_mapping_file:\n",
    "        pickle.dump(id_mapping, id_mapping_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = r'C:\\Users\\prati\\OneDrive\\Desktop\\Project\\joined_data_set.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    preprocess_and_build_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00056ee9-9558-4e2d-818e-afad886043ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
